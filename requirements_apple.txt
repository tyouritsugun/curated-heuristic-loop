# CHL API Server - Apple Silicon (Metal) with GPU acceleration
#
# This requirements file is for the API server running on Apple Silicon Macs
# with Metal GPU acceleration for embeddings and vector search.
#
# Prerequisites:
#   - macOS with Apple Silicon (M1, M2, M3, etc.)
#   - Xcode Command Line Tools installed
#
# Installation:
#   python -m venv .venv-apple
#   source .venv-apple/bin/activate
#   python -m pip install --upgrade pip
#   PIP_EXTRA_INDEX_URL=https://abetlen.github.io/llama-cpp-python/whl/metal \
#     python -m pip install -r requirements_apple.txt
#
# Starting the API server:
#   CHL_SEARCH_MODE=gpu python -m uvicorn src.api.server:app --host 127.0.0.1 --port 8000
#
# Note: The MCP server is installed separately via `uv sync` from pyproject.toml
# and communicates with this API server via HTTP.

# Web framework and server
fastapi>=0.114.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.6
jinja2>=3.1.0

# Database and ORM
sqlalchemy>=2.0.0

# HTTP client for external services
httpx>=0.27.0
requests>=2.31.0

# Google Sheets integration
gspread>=5.0.0
google-auth>=2.0.0
google-auth-oauthlib>=1.0.0

# Data processing and utilities
numpy>=1.24.0,<2.0.0
pyyaml>=6.0
python-dotenv>=1.0.0
pydantic>=2.6.0
tqdm>=4.65.0
tenacity>=8.2.0
markdown>=3.6

# ML / GPU stack (Metal-accelerated)
faiss-cpu>=1.7.4
huggingface-hub>=0.20.0
sentence-transformers>=3.1.1
# llama-cpp-python with Metal support from abetlen's wheel index
llama-cpp-python==0.3.16
