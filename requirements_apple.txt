# CHL API Server - Apple Silicon (Metal) with GPU acceleration
#
# This requirements file is for the API server running on Apple Silicon Macs
# with Metal GPU acceleration for embeddings and vector search.
#
# Prerequisites:
#   - macOS with Apple Silicon (M1, M2, M3, etc.)
#   - Xcode Command Line Tools installed
#
# Installation:
#   python -m venv .venv-apple
#   source .venv-apple/bin/activate
#   python -m pip install --upgrade pip
#   PIP_EXTRA_INDEX_URL=https://abetlen.github.io/llama-cpp-python/whl/metal \
#     python -m pip install -r requirements_apple.txt
#
# Starting the API server:
#   python -m uvicorn src.api.server:app --host 127.0.0.1 --port 8000
#   (Backend is automatically configured from data/runtime_config.json)
#
# Note: The MCP server is installed separately via `uv sync` from pyproject.toml
# and communicates with this API server via HTTP.

# Web framework and server
fastapi>=0.114.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.6
jinja2>=3.1.0

# Database and ORM
sqlalchemy>=2.0.0

# HTTP client for external services
httpx>=0.27.0
requests>=2.31.0

# Google Sheets integration
gspread>=5.0.0
google-auth>=2.0.0
google-auth-oauthlib>=1.0.0

# Data processing and utilities
numpy>=1.24.0,<2.0.0
pandas>=2.0.0
openpyxl>=3.0.0
pyyaml>=6.0
python-dotenv>=1.0.0
pydantic>=2.6.0
tqdm>=4.65.0
tenacity>=8.2.0
markdown>=3.6

# ML stack (HF-based embeddings/reranker)
faiss-cpu>=1.8.0
huggingface-hub>=0.20.0
sentence-transformers>=3.1.1
torch>=2.3.0
transformers>=4.51.0
accelerate>=0.31.0
# (llama-cpp-python not required; HF-only stack)
